{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7izWfaHRtfUx"
   },
   "outputs": [],
   "source": [
    "def pagerank(G, alpha=0.85, personalization=None, max_iter=100, tol=1.0e-6, nstart=None, weight='weight', dangling=None):\n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "\n",
    "    if not G.is_directed():\n",
    "        D = G.to_directed()\n",
    "    else:\n",
    "        D = G\n",
    "\n",
    "    # Create a copy in (right) stochastic form\n",
    "    W = nx.stochastic_graph(D, weight=weight)\n",
    "    N = W.number_of_nodes()\n",
    "\n",
    "    # Choose fixed starting vector if not given\n",
    "    if nstart is None:\n",
    "        x = dict.fromkeys(W, 1.0 / N)\n",
    "    else:\n",
    "        # Normalized nstart vector\n",
    "        s = float(sum(nstart.values()))\n",
    "        x = dict((k, v / s) for k, v in nstart.items())\n",
    "\n",
    "    if personalization is None:\n",
    "        # Assign uniform personalization vector if not given\n",
    "        p = dict.fromkeys(W, 1.0 / N)\n",
    "    else:\n",
    "        missing = set(G) - set(personalization)\n",
    "        if missing:\n",
    "            raise NetworkXError('Personalization dictionary must have a value for every node. Missing nodes %s' % missing)\n",
    "        s = float(sum(personalization.values()))\n",
    "        p = dict((k, v / s) for k, v in personalization.items())\n",
    "\n",
    "    if dangling is None:\n",
    "        # Use personalization vector if dangling vector not specified\n",
    "        dangling_weights = p\n",
    "    else:\n",
    "        missing = set(G) - set(dangling)\n",
    "        if missing:\n",
    "            raise NetworkXError('Dangling node dictionary must have a value for every node. Missing nodes %s' % missing)\n",
    "        s = float(sum(dangling.values()))\n",
    "        dangling_weights = dict((k, v/s) for k, v in dangling.items())\n",
    "\n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
    "\n",
    "     # power iteration: make up to max_iter iterations\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x\n",
    "        x = dict.fromkeys(xlast.keys(), 0)\n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes)\n",
    "        for n in x:\n",
    "            # this matrix multiply looks odd because it is\n",
    "            # doing a left multiply x^T=xlast^T*W\n",
    "            for nbr in W[n]:\n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight]\n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n]\n",
    "\n",
    "        # check convergence, l1 norm\n",
    "        err = sum([abs(x[n] - xlast[n]) for n in x])\n",
    "        if err < N*tol:\n",
    "            return x\n",
    "    raise NetworkXError('Pagerank: power iteration failed to converge in %d iterations.' % max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4IpjHLg4tstL"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dc1k1Q5Htoyd"
   },
   "outputs": [],
   "source": [
    "G = nx.barabasi_albert_graph(60, 41)\n",
    "pr = nx.pagerank(G, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnUjtCjztuhi",
    "outputId": "11c54bc9-336b-4be6-f3c9-e3ec0c510819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.028021904170395837, 1: 0.013185687231096605, 2: 0.012983207363138809, 3: 0.013379255853104883, 4: 0.013378275383244737, 5: 0.012156164727199603, 6: 0.01295631566105917, 7: 0.013185888828345677, 8: 0.012156972723585985, 9: 0.013161022713540266, 10: 0.013389435563468478, 11: 0.012969058513021941, 12: 0.012974583609320507, 13: 0.01339153934510063, 14: 0.012960079900033623, 15: 0.013367125930426795, 16: 0.013180679923208104, 17: 0.012752807815346715, 18: 0.0127663876898628, 19: 0.012593767072567864, 20: 0.013384572068285408, 21: 0.01197573532875651, 22: 0.01318112600098929, 23: 0.012969664102294443, 24: 0.013395116206873043, 25: 0.013590170701681874, 26: 0.01218222505786245, 27: 0.012363471852394113, 28: 0.012352465090185673, 29: 0.012971662568874016, 30: 0.013588101947637717, 31: 0.012394550334661851, 32: 0.012560097308081199, 33: 0.013385126211212668, 34: 0.01337392999619621, 35: 0.012981930453743898, 36: 0.01297171687690417, 37: 0.012953790980418581, 38: 0.012973307194770096, 39: 0.013163149872450278, 40: 0.012969593441978296, 41: 0.013386331915037544, 42: 0.02760833973484287, 43: 0.027220232937959013, 44: 0.0269879722931926, 45: 0.026563512210541998, 46: 0.025727713721345913, 47: 0.025525272980017638, 48: 0.025264800872045766, 49: 0.02502742834152348, 50: 0.024795310806184634, 51: 0.024079332178641083, 52: 0.023828368510993105, 53: 0.023365218480257972, 54: 0.023440803976998537, 55: 0.022414761298643483, 56: 0.022444903205678823, 57: 0.02221976136663193, 58: 0.022116799852739875, 59: 0.021391471703402977}\n"
     ]
    }
   ],
   "source": [
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0xnf-ZctvtC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
